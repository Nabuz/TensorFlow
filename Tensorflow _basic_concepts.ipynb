{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabu-pc\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VERY SIMPLE SESSION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3, name =\"x\")\n",
    "y = tf.Variable(4, name =\"y\")\n",
    "f= x*x*y + y +2   #here we don't calculate ANYTHING!!!\n",
    "\n",
    "sess = tf.Session()  #we create a session\n",
    "sess.run(x.initializer) #we inizialize the variables\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f) # HERE WE CALCULATE F() !!!\n",
    "print(result)\n",
    "sess.close() #Here we close the session!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USING WITH BLOCK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use with block. Two benefits : 1- the session is automatically closed when with finishes \n",
    "                                       #2- the session is set as default session\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run() #it's equivalent to tf.get_default_session().run(x.initializer)\n",
    "    y.initializer.run() \n",
    "    result = f.eval() # it's equivalent to calling tf.get_default_session().run(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOBAL VARIABLES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With global_variable_initializer() you don't have to inizialize every single variable\n",
    "\n",
    "init = tf.global_variables_initializer()  #We prepare an init node. Here we don't initialize the variables!!!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() #actually initialize all the variables\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INTERACTIVE SESSION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Interactive session is different from a normal session: it is sets itself as the default session. So you don't need\n",
    "# a with block\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()  #we need to close the session!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PERFORMING A LINEAR REGRESSION: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabu-pc\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_2:0\", shape=(9, 1), dtype=float32)\n",
      ".........\n",
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]  #adding an extra feature with all 1 to all training instances\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")   #We create two Tensorflow constant nodes: data and targets\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)  # A vector (1-D) of Theta values \n",
    "                                                                       # Linear Algebra form (vector form): (XT*X)^-1*XT*y\n",
    "                                                                       # Here we DON'T CALCULATE theta vector\n",
    "                                                                       \n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()   # Here we calculate Theta vector!!!\n",
    "    \n",
    "print(theta)\n",
    "print(\".........\")\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCTION FOR CALCULATING GRADIENT MINI-BATCH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  \n",
    "    indices = np.random.randint(m, size=batch_size) #shape (batch_size,1) ,returns a vector of random integer from a continous distribution in a half open interval [)\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # range of above random values are in the range [0,m)\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CALCULATING THE GRADIENT MANUALLY WITH SAVING/RESTORING  (AND USING TENSORBOARD !!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\") #now = time in a specific format (YYYYMMDDHHMMSS)\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now ) # The path where we save the data: tf_logs/run-YYYYMMDDHHMMSS\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))  #int(arrotonda per eccesso(m/batch_size))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(housing_data_plus_bias)\n",
    "scaled_housing_data_plus_bias  =scaler.transform(housing_data_plus_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n + 1), name = \"X\") # We inserts a placeholder for a tensor that will be ALWAYS fed (alimentato) \n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = \"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0, 1.0), name = \"theta\") # A tensor (variable) with shape (9,1) that takes random values from a uniform distribution .Values in the range (-1,1). \n",
    "y_pred = tf.matmul(X,theta, name =\"predictions\") #dot product -> X*theta. Shape -> (m,9)*(9,1) -> (m,1) \n",
    "\n",
    "with tf.name_scope(\"loss\") as scope:    \n",
    "    error = y_pred - y # Shape : (m,1)\n",
    "    mse = tf.reduce_mean(tf.square(error), name =\"mse\")\n",
    "\n",
    "gradients = 2/m*tf.matmul(tf.transpose(X), error)  # dot product XT*error -> (n,m)*(m,1) -> (n,1) -> a vector with Gradient values\n",
    "training_op = tf.assign(theta, theta - learning_rate*gradients) #assign function permits to modify a variable (theta)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()  #Here we create the save node!!!\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse) # Creates a node in the graph that will evaluate the MSE value and writes it to a TensoBoard-compatible binary log string called Summary\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph()) # We create a filewriter that you use to write summaries to logfiles in the log directory\n",
    "                                                                    # logdir = the patph of the logdir diretory. Second parameter = the graph we want to visualize\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\") #We create a checkpoint each 100 epoch\n",
    "        \n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index %10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op,feed_dict={X: X_batch, y: y_batch}) #x_batch: shape (batch_size,n-1), y_batch: shape (batch_size,1) \n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\" )\n",
    "    file_writer.close()\n",
    "\n",
    "# For running Tensorboard, in the Anaconda Prompt IN /Progetto Forex/Python (our working directory) -> tensorboard --logdir tf_logs\n",
    "    \n",
    "# to restore the saved variable:\n",
    "# with tf.Session() as sess:\n",
    "#     saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 303.933334,
   "position": {
    "height": "326px",
    "left": "1686.69px",
    "right": "20px",
    "top": "123.891px",
    "width": "435px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
